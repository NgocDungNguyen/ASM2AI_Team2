{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values before imputation:\n",
      "datetime              0\n",
      "tempmax               0\n",
      "tempmin               0\n",
      "temp                  0\n",
      "feelslikemax          0\n",
      "feelslikemin          0\n",
      "feelslike             0\n",
      "dew                   0\n",
      "humidity              0\n",
      "precip                0\n",
      "precipprob            0\n",
      "precipcover           0\n",
      "preciptype          386\n",
      "snow                  0\n",
      "snowdepth             0\n",
      "windgust              0\n",
      "windspeed             0\n",
      "winddir               0\n",
      "sealevelpressure      0\n",
      "cloudcover            0\n",
      "visibility            0\n",
      "solarradiation        0\n",
      "solarenergy           0\n",
      "uvindex               0\n",
      "severerisk           40\n",
      "sunrise               0\n",
      "sunset                0\n",
      "moonphase             0\n",
      "conditions            0\n",
      "dtype: int64\n",
      "\n",
      "Shape of data after removing outliers: (1000, 29)\n",
      "\n",
      "Missing values after imputation:\n",
      "datetime            0\n",
      "tempmax             0\n",
      "tempmin             0\n",
      "temp                0\n",
      "feelslikemax        0\n",
      "feelslikemin        0\n",
      "feelslike           0\n",
      "dew                 0\n",
      "humidity            0\n",
      "precip              0\n",
      "precipprob          0\n",
      "precipcover         0\n",
      "preciptype          0\n",
      "snow                0\n",
      "snowdepth           0\n",
      "windgust            0\n",
      "windspeed           0\n",
      "winddir             0\n",
      "sealevelpressure    0\n",
      "cloudcover          0\n",
      "visibility          0\n",
      "solarradiation      0\n",
      "solarenergy         0\n",
      "uvindex             0\n",
      "severerisk          0\n",
      "sunrise             0\n",
      "sunset              0\n",
      "moonphase           0\n",
      "conditions          0\n",
      "dtype: int64\n",
      "\n",
      "____________ Dataset info ____________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 29 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   datetime          1000 non-null   datetime64[ns]\n",
      " 1   tempmax           1000 non-null   float64       \n",
      " 2   tempmin           1000 non-null   float64       \n",
      " 3   temp              1000 non-null   float64       \n",
      " 4   feelslikemax      1000 non-null   float64       \n",
      " 5   feelslikemin      1000 non-null   float64       \n",
      " 6   feelslike         1000 non-null   float64       \n",
      " 7   dew               1000 non-null   float64       \n",
      " 8   humidity          1000 non-null   float64       \n",
      " 9   precip            1000 non-null   float64       \n",
      " 10  precipprob        1000 non-null   int64         \n",
      " 11  precipcover       1000 non-null   float64       \n",
      " 12  preciptype        1000 non-null   object        \n",
      " 13  snow              1000 non-null   float64       \n",
      " 14  snowdepth         1000 non-null   float64       \n",
      " 15  windgust          1000 non-null   float64       \n",
      " 16  windspeed         1000 non-null   float64       \n",
      " 17  winddir           1000 non-null   float64       \n",
      " 18  sealevelpressure  1000 non-null   float64       \n",
      " 19  cloudcover        1000 non-null   float64       \n",
      " 20  visibility        1000 non-null   float64       \n",
      " 21  solarradiation    1000 non-null   float64       \n",
      " 22  solarenergy       1000 non-null   float64       \n",
      " 23  uvindex           1000 non-null   int64         \n",
      " 24  severerisk        1000 non-null   float64       \n",
      " 25  sunrise           1000 non-null   object        \n",
      " 26  sunset            1000 non-null   object        \n",
      " 27  moonphase         1000 non-null   float64       \n",
      " 28  conditions        1000 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(22), int64(2), object(4)\n",
      "memory usage: 226.7+ KB\n",
      "None\n",
      "\n",
      "____________ Some first data examples ____________\n",
      "    datetime  tempmax  tempmin  temp  feelslikemax  feelslikemin  feelslike  \\\n",
      "0 2021-12-01      9.4      4.8   7.2           9.2           1.0        5.5   \n",
      "1 2021-12-02     14.5      7.5  11.9          14.5           5.7       11.5   \n",
      "2 2021-12-03      9.2      3.6   6.7           6.9           0.9        3.6   \n",
      "\n",
      "   dew  humidity  precip  ...  cloudcover  visibility solarradiation  \\\n",
      "0 -3.4      47.4   0.000  ...        42.2        16.0           99.5   \n",
      "1  5.4      65.8   0.893  ...        68.1        15.6           48.0   \n",
      "2 -5.0      43.3   0.000  ...        16.3        16.0          106.8   \n",
      "\n",
      "   solarenergy  uvindex  severerisk              sunrise               sunset  \\\n",
      "0          8.6        5        10.0  2021-12-01T07:01:04  2021-12-01T16:29:10   \n",
      "1          4.2        3        10.0  2021-12-02T07:02:05  2021-12-02T16:28:57   \n",
      "2          9.1        5        10.0  2021-12-03T07:03:04  2021-12-03T16:28:45   \n",
      "\n",
      "   moonphase              conditions  \n",
      "0       0.91        Partially cloudy  \n",
      "1       0.95  Rain, Partially cloudy  \n",
      "2       0.98                   Clear  \n",
      "\n",
      "[3 rows x 29 columns]\n",
      "\n",
      "____________ Statistics of numeric features ____________\n",
      "                  datetime      tempmax      tempmin         temp  \\\n",
      "count                 1000  1000.000000  1000.000000  1000.000000   \n",
      "mean   2023-04-14 12:00:00    17.962500    10.794900    14.072100   \n",
      "min    2021-12-01 00:00:00    -9.300000   -14.200000   -11.600000   \n",
      "25%    2022-08-07 18:00:00    10.000000     3.800000     6.800000   \n",
      "50%    2023-04-14 12:00:00    17.800000    10.000000    13.700000   \n",
      "75%    2023-12-20 06:00:00    26.600000    18.800000    22.325000   \n",
      "max    2024-08-26 00:00:00    36.100000    26.700000    30.700000   \n",
      "std                    NaN     9.463544     8.744772     8.879228   \n",
      "\n",
      "       feelslikemax  feelslikemin    feelslike          dew     humidity  \\\n",
      "count   1000.000000   1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      17.809200      9.136000    13.208900     6.397600    62.516800   \n",
      "min      -15.800000    -26.000000   -20.200000   -21.200000    24.300000   \n",
      "25%        9.400000      0.775000     5.000000    -1.200000    51.900000   \n",
      "50%       17.800000     10.000000    13.650000     6.900000    61.700000   \n",
      "75%       26.525000     18.800000    22.325000    14.500000    73.525000   \n",
      "max       41.000000     29.500000    34.700000    24.000000    95.400000   \n",
      "std       10.539795     10.566489    10.257902     9.620034    14.431138   \n",
      "\n",
      "            precip  ...    windspeed      winddir  sealevelpressure  \\\n",
      "count  1000.000000  ...  1000.000000  1000.000000       1000.000000   \n",
      "mean      1.307078  ...    20.452500   190.882400       1016.448400   \n",
      "min       0.000000  ...     8.000000     0.200000        989.900000   \n",
      "25%       0.000000  ...    15.900000    75.600000       1011.900000   \n",
      "50%       0.000000  ...    19.450000   231.400000       1016.300000   \n",
      "75%       0.469000  ...    24.000000   270.125000       1021.100000   \n",
      "max      60.941000  ...    46.400000   359.800000       1037.200000   \n",
      "std       4.390026  ...     6.424748   103.137534          7.411559   \n",
      "\n",
      "        cloudcover   visibility  solarradiation  solarenergy      uvindex  \\\n",
      "count  1000.000000  1000.000000     1000.000000  1000.000000  1000.000000   \n",
      "mean     43.695200    15.045500      156.606300    13.520300     6.170000   \n",
      "min       0.100000     4.100000        0.000000     0.000000     0.000000   \n",
      "25%      14.075000    15.100000       78.075000     6.700000     4.000000   \n",
      "50%      37.150000    15.900000      148.200000    12.700000     6.000000   \n",
      "75%      72.425000    16.000000      237.725000    20.600000     9.000000   \n",
      "max     100.000000    16.000000      353.100000    30.600000    10.000000   \n",
      "std      32.501548     1.829007       93.909789     8.117261     2.962073   \n",
      "\n",
      "        severerisk    moonphase  \n",
      "count  1000.000000  1000.000000  \n",
      "mean     14.550000     0.481630  \n",
      "min      10.000000     0.000000  \n",
      "25%      10.000000     0.250000  \n",
      "50%      10.000000     0.480000  \n",
      "75%      10.000000     0.740000  \n",
      "max     100.000000     0.980000  \n",
      "std      13.308818     0.288554  \n",
      "\n",
      "[8 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
      "C:\\Users\\June Nguyen\\AppData\\Local\\Temp\\ipykernel_7760\\8986900.py:57: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  raw_data[column].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "____________ Train and Evaluate Models ____________\n",
      "RandomForestReg      RMSE before tuning: 0.5292\n",
      "GradientBoostingReg  RMSE before tuning: 0.9778\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 17.578500\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LGBMReg              RMSE before tuning: 0.6710\n",
      "XGBBoost             RMSE before tuning: 0.0964\n",
      "SVR                  RMSE before tuning: 1.9776\n",
      "ElasticNet           RMSE before tuning: 3.6741\n",
      "Lasso                RMSE before tuning: 1.8004\n",
      "Ridge                RMSE before tuning: 1.2780\n",
      "MLPRegressor         RMSE before tuning: 1.3025\n",
      "\n",
      "____________ Fine-tune models ____________\n",
      "\n",
      "Fine-tuning RandomForestReg\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for RandomForestReg: 1.4983\n",
      "RandomForestReg is not improved after tuning. Using untuned version.\n",
      "\n",
      "Fine-tuning GradientBoostingReg\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for GradientBoostingReg: 1.4581\n",
      "GradientBoostingReg is not improved after tuning. Using untuned version.\n",
      "\n",
      "Fine-tuning LGBMReg\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1033\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 17.578500\n",
      "Best RMSE for LGBMReg: 1.6289\n",
      "LGBMReg is not improved after tuning. Using untuned version.\n",
      "\n",
      "Fine-tuning XGBBoost\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for XGBBoost: 1.4878\n",
      "XGBBoost is not improved after tuning. Using untuned version.\n",
      "\n",
      "Fine-tuning SVR\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for SVR: 1.3594\n",
      "SVR is improved after tuning. Using tuned version.\n",
      "\n",
      "Fine-tuning ElasticNet\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for ElasticNet: 1.3521\n",
      "ElasticNet is improved after tuning. Using tuned version.\n",
      "\n",
      "Fine-tuning Lasso\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for Lasso: 1.3535\n",
      "Lasso is improved after tuning. Using tuned version.\n",
      "\n",
      "Fine-tuning Ridge\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for Ridge: 1.3656\n",
      "Ridge is not improved after tuning. Using untuned version.\n",
      "\n",
      "Fine-tuning MLPRegressor\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best RMSE for MLPRegressor: 1.6770\n",
      "MLPRegressor is not improved after tuning. Using untuned version.\n",
      "\n",
      "Best model after fine-tuning: XGBBoost with RMSE: 0.0964\n",
      "\n",
      "Performance on test data: RMSE: 1.4014\n",
      "Future predictions have been saved to 'future_predictions_200days.csv'\n",
      "\n",
      "Predicted Max Temperature:\n",
      "Min: -2.29°C\n",
      "Max: 33.42°C\n",
      "Avg: 14.11°C\n",
      "\n",
      "____________ CONCLUSION ____________\n",
      "\n",
      "1. Data Preprocessing:\n",
      "   - Removed outliers and handled missing values.\n",
      "   - Added engineered features: day of year, month, day of week, is_weekend.\n",
      "   - Applied scaling and one-hot encoding.\n",
      "\n",
      "2. Model Selection and Hyperparameter Tuning:\n",
      "   - Evaluated multiple models using RMSE as the sole metric.\n",
      "   - Used RandomizedSearchCV for hyperparameter optimization.\n",
      "   - The best performing model was: XGBBoost\n",
      "\n",
      "3. Model Performance:\n",
      "   - Best model RMSE on test data: 1.4014\n",
      "\n",
      "4. Future Predictions:\n",
      "   - Generated predictions for the next 200 days.\n",
      "   - The predicted temperatures range from -2.29°C to 33.42°C.\n",
      "\n",
      "Suggestions for Further Improvement:\n",
      "1. Collect more historical data or external data sources.\n",
      "2. Experiment with more advanced time series models.\n",
      "3. Implement online learning for continuous model updates.\n",
      "4. Consider using deep learning models for complex pattern capture.\n",
      "5. Analyze prediction intervals for more robust forecasts.\n",
      "\n",
      "\n",
      "Prediction and analysis complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In[0]: IMPORT AND FUNCTIONS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from scipy.stats import randint, uniform\n",
    "from datetime import timedelta\n",
    "import joblib\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('saved_objects', exist_ok=True)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# In[1]: LOAD DATA AND INITIAL PREPROCESSING\n",
    "raw_data = pd.read_csv('datasets/NewYork.csv')\n",
    "raw_data['datetime'] = pd.to_datetime(raw_data['datetime'])\n",
    "raw_data.drop(columns=[\"name\", \"icon\", \"stations\", \"description\"], inplace=True)\n",
    "\n",
    "print(\"\\nMissing values before imputation:\")\n",
    "print(raw_data.isnull().sum())\n",
    "\n",
    "def remove_outliers(df, column, factor=1.5):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - factor * IQR\n",
    "    upper_bound = Q3 + factor * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "raw_data = remove_outliers(raw_data, 'tempmax')\n",
    "print(\"\\nShape of data after removing outliers:\", raw_data.shape)\n",
    "\n",
    "for column in raw_data.columns:\n",
    "    if raw_data[column].dtype == 'object':\n",
    "        raw_data[column].fillna('Unknown', inplace=True)\n",
    "    else:\n",
    "        raw_data[column].fillna(raw_data[column].median(), inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(raw_data.isnull().sum())\n",
    "\n",
    "# In[2]: DISCOVER THE DATA\n",
    "print('\\n____________ Dataset info ____________')\n",
    "print(raw_data.info())              \n",
    "print('\\n____________ Some first data examples ____________')\n",
    "print(raw_data.head(3)) \n",
    "print('\\n____________ Statistics of numeric features ____________')\n",
    "print(raw_data.describe())    \n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = raw_data.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/correlation_heatmap.png', format='png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Histogram of all numeric features\n",
    "numeric_features = raw_data.select_dtypes(include=[np.number]).columns\n",
    "n_features = len(numeric_features)\n",
    "n_rows = (n_features + 1) // 2\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(n_rows, 2, i)\n",
    "    sns.histplot(raw_data[feature], kde=True)\n",
    "    plt.title(f'Distribution of {feature}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/hist_raw_data.png', format='png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Scatter plots of tempmax vs other numeric features\n",
    "numeric_features = [col for col in numeric_features if col != 'tempmax']\n",
    "n_features = len(numeric_features)\n",
    "n_rows = (n_features + 1) // 2\n",
    "plt.figure(figsize=(15, 5 * n_rows))\n",
    "for i, feature in enumerate(numeric_features, 1):\n",
    "    plt.subplot(n_rows, 2, i)\n",
    "    sns.scatterplot(data=raw_data, x=feature, y='tempmax', alpha=0.5)\n",
    "    plt.title(f'Max Temperature vs {feature}')\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/scatter_tempmax_vs_features.png', format='png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Pairplot of main features\n",
    "main_features = ['tempmax', 'temp', 'humidity', 'windspeed', 'cloudcover']\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.pairplot(raw_data[main_features], diag_kind='kde')\n",
    "plt.suptitle(\"Pairplot of Main Features\", y=1.02)\n",
    "plt.savefig('figures/pairplot_main_features.png', format='png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# In[3]: PREPARE THE DATA \n",
    "class EnhancedFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_features=True):\n",
    "        self.add_features = add_features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_ = X.copy()\n",
    "        if self.add_features:\n",
    "            X_['day_of_year'] = X_['datetime'].dt.dayofyear\n",
    "            X_['month'] = X_['datetime'].dt.month\n",
    "            X_['day_of_week'] = X_['datetime'].dt.dayofweek\n",
    "            X_['is_weekend'] = X_['day_of_week'].isin([5, 6]).astype(int)\n",
    "        return X_.drop('datetime', axis=1)\n",
    "\n",
    "numeric_features = ['temp', 'humidity', 'precip', 'windspeed', 'cloudcover']\n",
    "categorical_features = ['conditions', 'preciptype']\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "enhanced_pipeline = Pipeline([\n",
    "    ('feature_adder', EnhancedFeatureAdder()),\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "X = raw_data.drop('tempmax', axis=1)\n",
    "y = raw_data['tempmax']\n",
    "\n",
    "X_processed = enhanced_pipeline.fit_transform(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# In[4]: TRAIN AND EVALUATE MODELS\n",
    "models = {\n",
    "    'RandomForestReg': RandomForestRegressor(random_state=42),\n",
    "    'GradientBoostingReg': GradientBoostingRegressor(random_state=42),\n",
    "    'LGBMReg': LGBMRegressor(random_state=42),\n",
    "    'XGBBoost': XGBRegressor(random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'ElasticNet': ElasticNet(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'MLPRegressor': MLPRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "def evaluate_model(model, data, labels): \n",
    "    prediction = model.predict(data)\n",
    "    rmse = np.sqrt(mean_squared_error(labels, prediction))\n",
    "    return rmse\n",
    "\n",
    "# Store RMSE for untuned models\n",
    "rmse_before_tuning = {}\n",
    "\n",
    "print('\\n____________ Train and Evaluate Models ____________')\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    rmse = evaluate_model(model, X_train, y_train)\n",
    "    rmse_before_tuning[name] = rmse\n",
    "    print(f'{name:<20} RMSE before tuning: {rmse:.4f}')\n",
    "\n",
    "# In[5]: FINE-TUNE MODELS\n",
    "print('\\n____________ Fine-tune models ____________')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "param_grids = {\n",
    "    'RandomForestReg': {\n",
    "        'n_estimators': randint(100, 1000),\n",
    "        'max_depth': randint(5, 30),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 20),\n",
    "        'max_features': uniform(0.1, 0.9)\n",
    "    },\n",
    "    'GradientBoostingReg': {\n",
    "        'n_estimators': randint(100, 1000),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 20),\n",
    "        'subsample': uniform(0.5, 0.5)\n",
    "    },\n",
    "    'LGBMReg': {\n",
    "        'num_leaves': randint(20, 100),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'n_estimators': randint(100, 1000),\n",
    "        'min_child_samples': randint(1, 50),\n",
    "        'subsample': uniform(0.5, 0.5),\n",
    "        'colsample_bytree': uniform(0.5, 0.5)\n",
    "    },\n",
    "    'XGBBoost': {\n",
    "        'n_estimators': randint(100, 1000),\n",
    "        'learning_rate': uniform(0.01, 0.2),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'min_child_weight': randint(1, 10),\n",
    "        'subsample': uniform(0.5, 0.5),\n",
    "        'colsample_bytree': uniform(0.5, 0.5),\n",
    "        'gamma': uniform(0, 0.5)\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': uniform(0.1, 100),\n",
    "        'kernel': ['rbf', 'linear', 'poly'],\n",
    "        'gamma': ['scale', 'auto'] + list(uniform(0.001, 0.1).rvs(10)),\n",
    "        'epsilon': uniform(0.01, 1)\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': uniform(0.001, 1),\n",
    "        'l1_ratio': uniform(0, 1),\n",
    "        'max_iter': [5000, 10000]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': uniform(0.001, 1),\n",
    "        'max_iter': [5000, 10000]\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': uniform(0.001, 1),\n",
    "        'max_iter': [5000, 10000]\n",
    "    },\n",
    "    'MLPRegressor': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "        'alpha': uniform(0.00001, 0.01),\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'max_iter': [1000, 2000],\n",
    "        'activation': ['relu', 'tanh']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nFine-tuning {name}\")\n",
    "    \n",
    "    grid_search = RandomizedSearchCV(model, param_distributions=param_grids[name], \n",
    "                                     n_iter=100, cv=tscv, \n",
    "                                     scoring='neg_mean_squared_error', n_jobs=-1, \n",
    "                                     random_state=42, verbose=1, error_score='raise')\n",
    "    try:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_rmse = np.sqrt(-grid_search.best_score_)\n",
    "        print(f\"Best RMSE for {name}: {best_rmse:.4f}\")\n",
    "        \n",
    "        # Compare RMSE before and after tuning\n",
    "        if best_rmse < rmse_before_tuning[name]:\n",
    "            print(f\"{name} is improved after tuning. Using tuned version.\")\n",
    "            best_models[name] = (grid_search.best_estimator_, best_rmse)\n",
    "        else:\n",
    "            print(f\"{name} is not improved after tuning. Using untuned version.\")\n",
    "            best_models[name] = (model, rmse_before_tuning[name])\n",
    "        \n",
    "        joblib.dump(grid_search, f'saved_objects/{name}_gridsearch.pkl')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while tuning {name}: {str(e)}\")\n",
    "        print(\"Skipping this model and continuing with the next one.\")\n",
    "\n",
    "# In[6]: SELECT BEST MODEL\n",
    "best_model_name = min(best_models, key=lambda name: best_models[name][1])\n",
    "best_model, best_rmse = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model after fine-tuning: {best_model_name} with RMSE: {best_rmse:.4f}\")\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'models/SOLUTION_model.pkl')\n",
    "\n",
    "# In[7]: ANALYZE AND TEST THE SOLUTION\n",
    "y_pred = best_model.predict(X_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'\\nPerformance on test data: RMSE: {test_rmse:.4f}')\n",
    "\n",
    "# In[8]: MAKE FUTURE PREDICTIONS\n",
    "last_date = raw_data['datetime'].max()\n",
    "future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=200)\n",
    "future_data = pd.DataFrame({'datetime': future_dates})\n",
    "\n",
    "def find_closest_date(target_date, data):\n",
    "    try:\n",
    "        target_date = target_date.replace(year=target_date.year - 1)\n",
    "    except ValueError:\n",
    "        target_date = target_date.replace(year=target_date.year - 1, day=28)\n",
    "    closest_date = data['datetime'].iloc[(data['datetime'] - target_date).abs().argsort()[0]]\n",
    "    return data.loc[data['datetime'] == closest_date].iloc[0]\n",
    "\n",
    "for col in raw_data.columns:\n",
    "    if col not in ['datetime', 'tempmax']:\n",
    "        future_data[col] = future_data['datetime'].apply(lambda x: find_closest_date(x, raw_data)[col])\n",
    "\n",
    "future_processed = enhanced_pipeline.transform(future_data)\n",
    "future_pred = best_model.predict(future_processed)\n",
    "future_data['predicted_tempmax'] = future_pred\n",
    "\n",
    "future_data[['datetime', 'predicted_tempmax']].to_csv('future_predictions_200days.csv', index=False)\n",
    "print(\"Future predictions have been saved to 'future_predictions_200days.csv'\")\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(future_data['datetime'], future_data['predicted_tempmax'], label='Predicted Max Temperature', alpha=0.7)\n",
    "plt.title('Predicted Maximum Temperature for the Next 200 Days')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/future_predictions_200days_plot.png', format='png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nPredicted Max Temperature:\")\n",
    "print(f\"Min: {future_data['predicted_tempmax'].min():.2f}°C\")\n",
    "print(f\"Max: {future_data['predicted_tempmax'].max():.2f}°C\")\n",
    "print(f\"Avg: {future_data['predicted_tempmax'].mean():.2f}°C\")\n",
    "\n",
    "# In[8]: CONCLUSION\n",
    "print(\"\\n____________ CONCLUSION ____________\")\n",
    "print(f\"\"\"\n",
    "1. Data Preprocessing:\n",
    "   - Removed outliers and handled missing values.\n",
    "   - Added engineered features: day of year, month, day of week, is_weekend.\n",
    "   - Applied scaling and one-hot encoding.\n",
    "\n",
    "2. Model Selection and Hyperparameter Tuning:\n",
    "   - Evaluated multiple models using RMSE as the sole metric.\n",
    "   - Used RandomizedSearchCV for hyperparameter optimization.\n",
    "   - The best performing model was: {best_model_name}\n",
    "\n",
    "3. Model Performance:\n",
    "   - Best model RMSE on test data: {test_rmse:.4f}\n",
    "\n",
    "4. Future Predictions:\n",
    "   - Generated predictions for the next 200 days.\n",
    "   - The predicted temperatures range from {future_data['predicted_tempmax'].min():.2f}°C to {future_data['predicted_tempmax'].max():.2f}°C.\n",
    "\n",
    "Suggestions for Further Improvement:\n",
    "1. Collect more historical data or external data sources.\n",
    "2. Experiment with more advanced time series models.\n",
    "3. Implement online learning for continuous model updates.\n",
    "4. Consider using deep learning models for complex pattern capture.\n",
    "5. Analyze prediction intervals for more robust forecasts.\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nPrediction and analysis complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
